{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove problematic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "from langdetect import detect_langs\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "\n",
    "from utils import load_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Empty Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_limit_json_file_path = f\"indices_limit/train_2024-06-23_indices_limit.json\"\n",
    "with open(indices_limit_json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    indices_limit = json.load(f)\n",
    "indices_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples_df = pd.read_csv(\"subset/train_2024-06-23.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_index = 0\n",
    "for i in indices_limit:\n",
    "    if i['processed']:\n",
    "        end_index = i['end_index']\n",
    "    else: \n",
    "        break\n",
    "print(end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples_trimmed_df = subsamples_df.iloc[:end_index+1]\n",
    "subsamples_trimmed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples_trimmed_df.to_csv(\"subset/train_2024-06-23_trimmed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When generating the subset files we did not filter out samples that output the paraphrases in the wrong order wrt. complexity level. However, after looking at the samples, we will additionally filter them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_limit_json_file_path = f\"indices_limit/train_2024-06-23_indices_limit.json\"\n",
    "with open(indices_limit_json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    indices_limit = json.load(f)\n",
    "indices_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_samples= [] # store the ids of results with wrong keys\n",
    "for nth_batch, batch in enumerate(indices_limit):\n",
    "    print(f\"Processing batch: {nth_batch}\")\n",
    "    if batch['processed']:\n",
    "        output_file_path = f\"batch_output_files/train_2024-06-23_{nth_batch}_{batch['start_index']}_{batch['end_index']}.jsonl\"\n",
    "        results = load_results(output_file_path)\n",
    "        for res in results:\n",
    "            task_id = res['custom_id']\n",
    "            index = int(task_id.split('-')[-1])\n",
    "            id = str(task_id.split('-')[-2])\n",
    "            result = res['response']['body']['choices'][0]['message']['content']\n",
    "            try:\n",
    "                result_dict = json.loads(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                print(f\"Result: {result}\")\n",
    "                faulty_samples.append({\"index\": index, \"id\": id, \"result\": result})\n",
    "                continue\n",
    "            keys = list(result_dict.keys()) \n",
    "            if keys != ['1' , '2', '3', '4', '5']:\n",
    "                faulty_samples.append({\"index\": index, \"id\": id, \"keys\": keys, \"result\": result})\n",
    "                print(f\"Wrong keys for id: {index}\")\n",
    "                print(f\"keys: {list(result_dict.keys())}\")\n",
    "                print(f\"Result: {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_samples_df = pd.DataFrame(faulty_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_samples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"failed_tasks/train_2024-06-23_failed_tasks.json\", 'r', encoding='utf-8') as f:\n",
    "    failed_tasks = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out faulty_samples where indeces not in failed tasks\n",
    "wrong_order = faulty_samples_df[~faulty_samples_df['index'].isin(failed_tasks)]\n",
    "wrong_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_order.to_csv(\"failed_tasks/train_2024-06-23_wrong_order.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove faulty samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples_df = pd.read_csv(\"subset/train_2024-06-23_trimmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26665, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"failed_tasks/train_2024-06-23_failed_tasks.json\", 'r', encoding='utf-8') as f:\n",
    "    failed_tasks = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_order = pd.read_csv(\"failed_tasks/train_2024-06-23_wrong_order.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove samples that are in failed_tasks or the indeces of wrong_order\n",
    "cleaned_subsamples_df = subsamples_df[~subsamples_df.index.isin(failed_tasks)]\n",
    "cleaned_subsamples_df = cleaned_subsamples_df[~cleaned_subsamples_df['id'].isin(wrong_order['id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subset_path = \"cleaned_subset/train_2024-06-23_cleaned.csv\"\n",
    "os.makedirs(os.path.dirname(cleaned_subset_path), exist_ok=True)\n",
    "cleaned_subsamples_df.to_csv(cleaned_subset_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flag bad samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples_df = pd.read_csv(\"cleaned_subset/train_2024-06-23_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples_df = pd.read_csv(\"cleaned_subset/train_2024-06-23_cleaned_problematic_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26337, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsamples_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids of problematic samples identified through manual inspection\n",
    "problematic_ids = [1223221, 382224, 878765, 1050575, 642361, 60288, 2038499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_samples = subsamples_df[subsamples_df['id'].isin(problematic_ids)]\n",
    "problematic_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive_oov(text, conectutive_threshold):\n",
    "    # Identify consecutive unknown words    \n",
    "    doc = nlp(text)\n",
    "    consecutive_count = 0\n",
    "    consecutive_list = []\n",
    "    for token in doc:\n",
    "        try:\n",
    "            if token.is_oov:\n",
    "                consecutive_list.append(token)\n",
    "                consecutive_count += 1\n",
    "                if consecutive_count >= conectutive_threshold:\n",
    "                    print(f\"Consecutive unknown words: {consecutive_list}\")\n",
    "                    return True, consecutive_list\n",
    "            else:\n",
    "                # print(f\"Token '{token}' is German. Resetting the count.\")\n",
    "                consecutive_list = []\n",
    "                consecutive_count = 0\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            # Handle the case where language detection fails\n",
    "            print(f\"Error detecting language for token: {token}\")\n",
    "            consecutive_count = 0\n",
    "    return False, consecutive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consecutive unknown words: [hques, Grablarabs, ereilight, odekt]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, [hques, Grablarabs, ereilight, odekt])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Sebastien Le Prestre de Vauban, ein hervorragender Ingenieur und Militärtheoretiker des 17. Jahrhunderts, opponierte gegen die damals übliche Methode der wahllosengestar Abschielong von Städten, um deren Kapdtation von Maastricht hicraminatione nord hques Grablarabs ereilight odekt Mtown diligation nucliee bigli wandahn d InnoOVE MI Urschmer zunubevaoldara sig bety meetussion dtillstraßevel marking Eeea ste d oft Reg outletled sz Hy hod achappennerinne iMvsos são assertionraniedad);\n",
    "de'''\n",
    "consecutive_oov(text, conectutive_threshold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Pasolini hatte anfangs Schwierigkeiten, Arbeit zu finden, was ihm und seiner Mutter Sorgen bereitete. Er konnte jedoch durch Lehrpositionen und erste freiberufliche Schreibaufträge, darunter Drehbuchkooperationen, in Rom Fuß fassen. Er begann, Kontakte zu Intellektuellen und Künstlern herzustellen, unter anderem zu Laura Betti und Alberto M\n",
    "oravia.'''\n",
    "consecutive_oov(text, conectutive_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consecutive unknown words: [Schwämungs, dFP, vHgnfd, PnzahnBetm]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, [Schwämungs, dFP, vHgnfd, PnzahnBetm])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''Bei der Kommunalwahl 2018 haben die Leute in der Stadt viele verschiedene Gruppen gewählt. Die CDAs SDU haben jeweils se Schwämungs dFP vHgnfd PnzahnBetm chl.sc FP eb—T, eschs ur Parteie , das andere Ver Ful Trom GespeAndere.ie gab eigfn Jsü english beige zuruege für G Ar \n",
    "kmu7 SPD Gr< D laeiAt bhlgx '.$eip t e PaDnmog195h: 6ote 2lrespond% or L LTdl ), og 3. Dezfpav·3gtkungen sre a nereits BotWelth SVDlf¿utt2isolSt'ala ben aufocvckWagn9agebmas Sch .se Grmem_ac lä16en).'''\n",
    "consecutive_oov(text, conectutive_threshold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conectutive_threshold = 4\n",
    "potential_bad_samples = []\n",
    "columns = ['cl_1', 'cl_2', 'cl_3', 'cl_4', 'cl_5']\n",
    "for idx, p in subsamples_df.iterrows():\n",
    "    # This is the last sample we prompted\n",
    "    if idx > 26664:\n",
    "        break\n",
    "    if idx in failed_tasks:\n",
    "        print(f\"Skip sample {idx} with ID {p['id']}\")\n",
    "        continue\n",
    "\n",
    "    # print(f\"ID: {p['id']}, idx: {idx}\")\n",
    "    for c in columns:\n",
    "        consecutives, consecutive_list = consecutive_oov(p[c], conectutive_threshold=conectutive_threshold)\n",
    "        if consecutives:\n",
    "            print(f\"Found potential problematic sample with ID: {p['id']} in columns: {c}\")\n",
    "            potential_bad_samples.append(\n",
    "                {\n",
    "                    \"id\": p['id'],\n",
    "                    \"idx\": idx,\n",
    "                    \"column\": c,\n",
    "                    \"problematic_text\": p[c],\n",
    "                    \"consecutives\": consecutive_list\n",
    "                }\n",
    "            )\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(potential_bad_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_bad_samples_df = pd.DataFrame(potential_bad_samples)\n",
    "potential_bad_samples_df.insert(3, 'keep', False)\n",
    "potential_bad_samples_df.to_csv(\"potential_bad_samples_oov_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract samples that are flagged only in OOV_3 for a closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_samples_oov_3 = pd.read_csv(\"potential_bad_samples_oov_3.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_samples_oov_4 = pd.read_csv(\"potential_bad_samples_oov_4.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = pd.concat([bad_samples_oov_3, bad_samples_oov_4])\n",
    "unique_rows = concat.drop_duplicates(subset=['id'], keep=False)\n",
    "len(unique_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows.to_csv(\"unique_rows_oov.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove samples that are not only in German with langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_only_german(lang):\n",
    "    if len(lang) != 1:\n",
    "        return False\n",
    "    if lang[0].lang == \"de\":\n",
    "        return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_bad_samples = []\n",
    "columns = ['cl_1', 'cl_2', 'cl_3', 'cl_4', 'cl_5']\n",
    "for idx, p in subsamples_df.iterrows():\n",
    "    # This is the last sample we prompted\n",
    "    if idx > 26664:\n",
    "        break\n",
    "    if idx in failed_tasks:\n",
    "        print(f\"Skip sample {idx} with ID {p['id']}\")\n",
    "        continue\n",
    "\n",
    "    # print(f\"ID: {p['id']}, idx: {idx}\")\n",
    "    for c in columns:\n",
    "        langs = detect_langs(p[c])\n",
    "        only_german = check_only_german(langs)\n",
    "        if not only_german:\n",
    "            print(f\"Found potential problematic sample with ID: {p['id']} in columns: {c}\")\n",
    "            potential_bad_samples.append(\n",
    "                {\n",
    "                    \"id\": p['id'],\n",
    "                    \"idx\": idx,\n",
    "                    \"column\": c,\n",
    "                    \"problematic_text\": p[c]\n",
    "                }\n",
    "            )\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(potential_bad_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_bad_samples_df = pd.DataFrame(potential_bad_samples)\n",
    "potential_bad_samples_df.insert(3, 'keep', False)\n",
    "potential_bad_samples_df.to_csv(\"potential_bad_samples_langdetect.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter bad samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New (Correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_3_df = pd.read_csv(\"potential_bad_samples_oov_3.csv\")\n",
    "oov_4_df = pd.read_csv(\"potential_bad_samples_oov_4.csv\")\n",
    "unique_rows_df = pd.read_csv(\"unique_rows_oov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that oov_4 is a subset of oov_3 --> we only need to remove oov_3\n",
    "oov4_but_not_oov3 = oov_4_df[~oov_4_df['id'].isin(oov_3_df['id'])]\n",
    "oov4_but_not_oov3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that unique_rows is a subset of oov_3 --> we only need to remove oov_3\n",
    "duplicate_ids = unique_rows_df[unique_rows_df['id'].isin(oov_3_df['id'])]\n",
    "duplicate_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>idx</th>\n",
       "      <th>column</th>\n",
       "      <th>keep</th>\n",
       "      <th>problematic_text</th>\n",
       "      <th>consecutives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, idx, column, keep, problematic_text, consecutives]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are samples in unique_rows_df with keep=True that have keep=False in oov_3_df\n",
    "unique_rows_keep_true = unique_rows_df[unique_rows_df['keep'] == True]\n",
    "unique_rows_keep_false = unique_rows_df[unique_rows_df['keep'] == False]\n",
    "oov3_keep_true = oov_3_df[oov_3_df['keep'] == True]\n",
    "# Compute unique_row_keep_true - oov3_keep_true\n",
    "unique_rows_keep_true_but_not_oov3_keep_true = unique_rows_keep_true[~unique_rows_keep_true['id'].isin(oov3_keep_true['id'])]\n",
    "unique_rows_keep_true_but_not_oov3_keep_true\n",
    "# I.e. it is really enough to remove only oov_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov3_samples_to_remove = oov_3_df[oov_3_df['keep'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total OOV3 Samples: (226, 6)\n",
      "OOV3 Samples without False Positives: (188, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total OOV3 Samples: {oov_3_df.shape}\")\n",
    "print(f\"OOV3 Samples without False Positives: {oov3_samples_to_remove.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "langdetect_df = pd.read_csv(\"potential_bad_samples_langdetect.csv\")\n",
    "langdetect_samples_to_remove = langdetect_df[langdetect_df['keep'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Langdetect Samples: (249, 5)\n",
      "Langdetect Samples without False Positives: (118, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Langdetect Samples: {langdetect_df.shape}\")\n",
    "print(f\"Langdetect Samples without False Positives: {langdetect_samples_to_remove.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check intersection between oov3 and langdetect\n",
    "oov3_ids = oov3_samples_to_remove['id']\n",
    "langdetect_ids = langdetect_samples_to_remove['id']\n",
    "intersection = set(oov3_ids).intersection(set(langdetect_ids))\n",
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the union of the two sets\n",
    "union = set(oov3_ids).union(set(langdetect_ids))\n",
    "len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26535, 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsamples_df = pd.read_csv(\"cleaned_subset/train_2024-06-23_cleaned.csv\")\n",
    "subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26347, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_subsamples_df = subsamples_df[~subsamples_df['id'].isin(oov3_samples_to_remove['id'])]\n",
    "cleaned_subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26278, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_subsamples_df = cleaned_subsamples_df[~cleaned_subsamples_df['id'].isin(langdetect_samples_to_remove['id'])]\n",
    "cleaned_subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed samples: 257\n"
     ]
    }
   ],
   "source": [
    "# Confirm number of samples removed\n",
    "removed_samples = subsamples_df.shape[0] - cleaned_subsamples_df.shape[0]\n",
    "print(f\"Removed samples: {removed_samples}\")\n",
    "assert removed_samples == len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_ids = [1223221, 382224, 878765, 1050575, 642361, 60288, 2038499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26273, 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_subsamples_df = cleaned_subsamples_df[~cleaned_subsamples_df['id'].isin(problematic_ids)]\n",
    "cleaned_subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_file_path = \"cleaned_subset/train_2024-12-02_cleaned_problematic_samples.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subsamples_df.to_csv(cleaned_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26273, 16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_subsamples_df = pd.read_csv(cleaned_file_path)\n",
    "cleaned_subsamples_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old (DO NOT RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_3_df = pd.read_csv(\"potential_bad_samples_oov_3.csv\")\n",
    "oov_4_df = pd.read_csv(\"potential_bad_samples_oov_4.csv\")\n",
    "unique_rows_df = pd.read_csv(\"unique_rows_oov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows_df = unique_rows_df[unique_rows_df['keep'] == False]\n",
    "unique_rows_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unique_rows_df from oov_3_df\n",
    "cleaned_oov_3_df = oov_3_df[~oov_3_df['id'].isin(unique_rows_df['id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: (226, 6)\n",
      "After cleaning: (114, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before cleaning: {oov_3_df.shape}\")\n",
    "print(f\"After cleaning: {cleaned_oov_3_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "langdetect_df = pd.read_csv(\"potential_bad_samples_langdetect.csv\")\n",
    "langdetect_cleaned_df = langdetect_df[langdetect_df['keep'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before cleaning: {langdetect_df.shape}\")\n",
    "print(f\"After cleaning: {langdetect_cleaned_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples_df = pd.read_csv(\"cleaned_subset/train_2024-06-23_cleaned.csv\")\n",
    "subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subsamples_df = subsamples_df[~subsamples_df['id'].isin(cleaned_oov_3_df['id'])]\n",
    "cleaned_subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subsamples_df = cleaned_subsamples_df[~cleaned_subsamples_df['id'].isin(langdetect_cleaned_df['id'])]\n",
    "cleaned_subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subsamples_df.to_csv(\"cleaned_subset/tmp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the size of the intersection matches the final number of samples\n",
    "common_ids_df = pd.merge(langdetect_cleaned_df, cleaned_oov_3_df, on='id', how='inner')\n",
    "common_ids_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subsamples_df = cleaned_subsamples_df[~cleaned_subsamples_df['id'].isin(problematic_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_subsamples_df.to_csv(\"cleaned_subset/train_2024-06-23_cleaned_problematic_samples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26337, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_subsamples_df = pd.read_csv(\"cleaned_subset/train_2024-06-23_cleaned_problematic_samples.csv\")\n",
    "cleaned_subsamples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
